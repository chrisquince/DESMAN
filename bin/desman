#!/usr/bin/env python3
import sys
import pandas as p
import numpy as np
import argparse
import logging

from numpy.random import RandomState

# user defined modules
import desman.Variant_Filter as vf
import desman.Init_NMFT as inmft
import desman.Desman_Utils as du
import desman.HaploSNP_Sampler as hsnp
import desman.Output_Results as outr

# C code for tau sampling
import sampletau


def main(argv):
    parser = argparse.ArgumentParser()
    parser.add_argument("variant_file", help="input SNP frequencies")

    parser.add_argument('-g', '--genomes', type=int, required=True,
                        help="specify the haplotype number")

    parser.add_argument('-f', '--filter_variants', nargs='?', const=3.84, type=float,
                        help='filters variants by negative binomial loge likelihood defaults to 3.84')

    parser.add_argument('-r', '--random_select', nargs='?', const=1e3, type=int,
                        help="selects subset of variants passing filter to build model and assigns others")

    parser.add_argument('-e', '--eta_file', type=open,
                        help="reads initial eta matrix from file")

    parser.add_argument('-a', '--assign_file', type=open,
                        help="calculates haplotype profiles for these SNPs using fitted gamma, eta values")

    parser.add_argument('-o', '--output_dir', type=str, default="output",
                        help=("string specifying output directory and file stubs"))

    parser.add_argument('-p', '--optimiseP', default=True, type=bool,
                        help=("optimise proportions in likelihood ratio test"))

    parser.add_argument('-i', '--no_iter', nargs='?', const=250, type=int,
                        help='Number of iterations of Gibbs sampler')

    parser.add_argument('-m', '--min_coverage', type=float, default=5.0,
                        help='minimum coverage for sample to be included')

    parser.add_argument('-q', '--max_qvalue', default=1.0e-3, type=float,
                        help="specifies q value cut-off for variant detection defaults 1.0e-3")

    parser.add_argument('-s', '--random_seed', default=23724839, type=int,
                        help="specifies seed for numpy random number generator defaults to 23724839 applied after random filtering")

    parser.add_argument('-v', '--min_variant_freq', nargs='?', const=0.01, type=float,
                        help="specifies minimum variant frequency defaults 0.01")

    # get command line arguments
    args = parser.parse_args()
    variant_file = args.variant_file
    assign_file = args.assign_file
    eta_file = args.eta_file
    filter_variants = args.filter_variants
    random_select = args.random_select
    output_dir = args.output_dir
    min_coverage = args.min_coverage
    optimiseP = args.optimiseP
    max_qvalue = args.max_qvalue

    genomes = args.genomes
    if genomes < 0:
        logging.error('Only positive haplotype number valid not  %d. Exiting!' % genomes)
        sys.exit(-1)

    no_iter = args.no_iter
    min_variant_freq = args.min_variant_freq

    # create output object and start logging
    output_Results = outr.Output_Results(output_dir)

    # create new random state with fixed seed
    logging.info('Set fixed seed for random position selection = 238329')
    prng = RandomState(238329)

    # read in snp variants
    variants = p.read_csv(variant_file, header=0, index_col=0)

    # import ipdb; ipdb.set_trace()

    # construct variant filter to only select most likely SNPS
    variant_Filter = vf.Variant_Filter(variants, randomState=prng, optimise=optimiseP, threshold=filter_variants,
                                       min_coverage=min_coverage, qvalue_cutoff=max_qvalue)
    if variant_Filter.S < 1 or variant_Filter.V < 1:
        logging.error('Not enough samples with minimum coverage %d or variant positions %d. Exiting!' % (
        variant_Filter.S, variant_Filter.V))
        sys.exit()

    logging.info('Running Desman with %d samples and %d variant positions finding %d genomes.' % (
    variant_Filter.S, variant_Filter.V, genomes))

    # perform variant filtering if -f selected
    if filter_variants is not None:
        logging.info(
            'Begun filtering variants with parameters: optimise probability = %s, lr threshold = %s, min. coverage = %s, q-value threshold = %s, min. variant frequency = %s'
            % (optimiseP, filter_variants, min_coverage, max_qvalue, min_variant_freq))

        variant_Filter.get_filtered_VariantsLogRatio()

        logging.info("Completed variant filtering")

        # set eta transition matrix if file provided
    if eta_file is not None:
        logging.info('Set eta error transition matrix from = %s' % eta_file)
        eta_df = p.read_csv(eta_file, header=0, index_col=0)
        variant_Filter.eta = eta_df.to_numpy()

    if random_select is not None:
        if random_select < variant_Filter.V:
            logging.info('Selected %d random variant positions to infer haplotypes from' % random_select)
            variant_Filter.select_Random(random_select)
        else:
            logging.info('Not enough variable positions for random selection %d >= %d using all' % (
            random_select, variant_Filter.V))
            random_select = None

    logging.info('Set second adjustable random seed = %d', args.random_seed)
    prng = RandomState(args.random_seed)
    sampletau.initRNG()
    sampletau.setRNG(args.random_seed)

    init_NMFT = inmft.Init_NMFT(variant_Filter.snps_filter, genomes, prng)
    logging.info('Perform NTF initialisation')
    init_NMFT.factorize()

    haplo_SNP = hsnp.HaploSNP_Sampler(variant_Filter.snps_filter, genomes, prng, max_iter=no_iter)

    haplo_SNP.tau = np.copy(init_NMFT.get_tau(), order='C')  # Necessary to have C-order for passing to Cython

    haplo_SNP.updateTauIndices()

    haplo_SNP.gamma = np.copy(init_NMFT.get_gamma(), order='C')

    haplo_SNP.eta = np.copy(variant_Filter.eta, order='C')

    logging.info('Start Gibbs sampler burn-in phase')
    haplo_SNP.update()
    # after burn-in phase remove degeneracies
    haplo_SNP.removeDegenerate()
    logging.info('Start Gibbs sampler sampling phase')
    haplo_SNP.update()

    # output results to files
    output_Results.set_Variants(variants)

    output_Results.set_Variant_Filter(variant_Filter)

    output_Results.set_haplo_SNP(haplo_SNP, genomes)

    output_Results.output_Filtered_Tau(haplo_SNP.tau_star)

    # compute estimate of posterior probabilities over tau
    meanTau = haplo_SNP.tauMean()
    output_Results.output_Tau_Mean(meanTau)

    output_Results.output_Gamma(haplo_SNP.gamma_star)

    gamma_mean = haplo_SNP.gammaMean()
    output_Results.output_Gamma_Mean(gamma_mean)

    output_Results.output_Eta(haplo_SNP.eta_star)

    eta_mean = haplo_SNP.etaMean()
    output_Results.output_Eta_Mean(eta_mean)

    output_Results.output_Selected_Variants()

    # If we selected random set now assign the rest
    if random_select is not None:
        VS = variant_Filter.snps_filter_original.shape[0]

        snps_notselected = variant_Filter.snps_filter_original[variant_Filter.selected != True, :]

        init_NMFT_NS = inmft.Init_NMFT(snps_notselected, haplo_SNP.G, haplo_SNP.randomState)

        init_NMFT_NS.gamma = np.transpose(haplo_SNP.gamma)
        logging.info('Perform NTF initialisation on not selected SNPs fixed gamma')
        init_NMFT_NS.factorize_tau()

        haplo_SNP_NS = hsnp.HaploSNP_Sampler(snps_notselected, haplo_SNP.G, haplo_SNP.randomState, max_iter=no_iter)

        haplo_SNP_NS.tau = init_NMFT_NS.get_tau()
        haplo_SNP_NS.updateTauIndices()
        haplo_SNP_NS.gamma_star = np.copy(haplo_SNP.gammaMean(), order='C')
        haplo_SNP_NS.eta_star = np.copy(haplo_SNP.etaMean(), order='C')
        haplo_SNP_NS.gamma_store = np.copy(haplo_SNP.gamma_store, order='C')
        haplo_SNP_NS.eta_store = np.copy(haplo_SNP.eta_store, order='C')

        logging.info('Start Gibbs sampler burn-in phase')
        haplo_SNP_NS.updateTau()
        logging.info('Start Gibbs sampler sampling phase')
        haplo_SNP_NS.updateTau()
        output_Results.outPredFit(haplo_SNP_NS, genomes)
        output_Results.output_collated_Tau(haplo_SNP_NS, variants)

    # assign if assignment file given
    if (assign_file != None):
        assigns = p.read_csv(assign_file, header=0, index_col=0)
        assigns_matrix = assigns.to_numpy()
        assigns_matrix = np.delete(assigns_matrix, 0, 1)
        import ipdb;
        ipdb.set_trace()

        (assignTau, confTau) = haplo_SNP.assignTau(assigns_matrix)
        snda = haplo_SNP.calculateSND(assignTau)

        assign_contig_names = assigns.index.tolist()
        assign_position = assigns['Position']

        AV = assigns_matrix.shape[0]
        assign_tau_res = np.reshape(assignTau, (AV, haplo_SNP.G * 4))
        assign_tau_df = p.DataFrame(assign_tau_res, index=assign_contig_names)
        conf_tau_df = p.DataFrame(confTau, index=assign_contig_names)

        assign_tau_df['Position'] = assign_position
        conf_tau_df['Position'] = assign_position

        cols = assign_tau_df.columns.tolist()
        cols = cols[-1:] + cols[:-1]

        assign_tau_df = assign_tau_df[cols]
        assign_tau_df.to_csv(output_dir + "/Assigned_Tau_star.csv")

        cols = conf_tau_df.columns.tolist()
        cols = cols[-1:] + cols[:-1]

        conf_tau_df = conf_tau_df[cols]
        conf_tau_df.to_csv(output_dir + "/Assigned_Tau_conf.csv")

    sampletau.freeRNG()


if __name__ == "__main__":
    main(sys.argv[1:])
