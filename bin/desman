import sys, getopt
import os
import pandas as p
import numpy as np
import scipy.stats as ss
import scipy as sp
import scipy.misc as spm
import math
import argparse
import cPickle
import copy
import logging

from operator import mul, div, eq, ne, add, ge, le, itemgetter
from itertools import izip
from numpy import array, log, exp
from scipy.special import gammaln
from scipy.optimize import minimize_scalar
from numpy.random import RandomState

#user defined modules
import desman.Variant_Filter as vf
import desman.Init_NMFT as inmft
import desman.Desman_Utils as du
import desman.HaploSNP_Sampler as hsnp
import desman.Output_Results as outr

#C code for tau sampling
import sampletau 

def main(argv):
    parser = argparse.ArgumentParser()
    parser.add_argument("variant_file", help="input SNP frequencies")

    parser.add_argument('-g','--genomes', type=int, required=True,
        help=("specify the haplotype number"))
        
    parser.add_argument('-f','--filter_variants',nargs='?', const=3.84, type=float, 
        help=("filters variants by negative binomial loge likelihood defaults to 3.84"))

    parser.add_argument('-r','--random_select',nargs='?', const=1e3, type=int, 
        help=("selects subset of variants passing filter to build model and assigns others"))

    parser.add_argument('-e','--eta_file', type=file, 
        help=("reads initial eta matrix from file"))

    parser.add_argument('-a','--assign_file', type=file, 
        help=("calculates haplotype profiles for these SNPs using fitted gamma, eta values"))
    
    parser.add_argument('-o','--output_dir', type=str, default="output",
        help=("string specifying output directory and file stubs"))
    
    parser.add_argument('-p', '--optimiseP', default=True, type=bool,
        help=("optimise proportions in likelihood ratio test"))
    
    parser.add_argument('-i','--no_iter',nargs='?', const=250, type=int, 
        help=("Number of iterations of Gibbs sampler"))
    
    parser.add_argument('-m','--min_coverage', type=float, default=5.0,
        help=("minimum coverage for sample to be included"))

    parser.add_argument('-q','--max_qvalue',default=1.0e-3, type=float, 
        help=("specifies q value cut-off for variant detection defaults 1.0e-3"))
    
    parser.add_argument('-s','--random_seed',default=23724839, type=int, 
        help=("specifies seed for numpy random number generator defaults to 23724839 applied after random filtering"))
    
    parser.add_argument('-v','--min_variant_freq',nargs='?', const=0.01, type=float, 
        help=("specifies minimum variant frequency defaults 0.01"))
    
    #get command line arguments  
    args = parser.parse_args()
    variant_file = args.variant_file
    assign_file = args.assign_file
    eta_file = args.eta_file
    filter_variants = args.filter_variants
    random_select = args.random_select
    output_dir = args.output_dir
    min_coverage = args.min_coverage
    optimiseP = args.optimiseP
    max_qvalue = args.max_qvalue
    
    genomes = args.genomes
    if genomes < 0:
        logging.error('Only positive haplotype number valid not  %d. Exiting!'%genomes)
        sys.exit(-1)
     
    no_iter = args.no_iter
    min_variant_freq = args.min_variant_freq
    
    #create output object and start logging
    output_Results = outr.Output_Results(output_dir)
    
    #create new random state with fixed seed
    logging.info('Set fixed seed for random position selection = 238329')
    prng = RandomState(238329)
    
    #read in snp variants
    variants    = p.read_csv(variant_file, header=0, index_col=0)

    #import ipdb; ipdb.set_trace()
    
    #construct variant filter to only select most likely SNPS
    variant_Filter = vf.Variant_Filter(variants, randomState = prng, optimise = optimiseP, threshold = filter_variants, min_coverage = min_coverage, qvalue_cutoff = max_qvalue)
    if variant_Filter.S < 1 or variant_Filter.V < 1:
        logging.error('Not enough samples with minimum coverage %d or variant positions %d. Exiting!'%(variant_Filter.S,variant_Filter.V))
        sys.exit(-1)  
    
    logging.info('Running Desman with %d samples and %d variant positions finding %d genomes.' %(variant_Filter.S,variant_Filter.V,genomes))
    
      
    #perform variant filtering if -f selected
    if filter_variants is not None:   
        logging.info('Begun filtering variants with parameters: optimise probability = %s, lr threshold = %s, min. coverage = %s, q-value threshold = %s, min. variant frequency = %s'
                     % (optimiseP, filter_variants, min_coverage, max_qvalue, min_variant_freq))

        variant_Filter.get_filtered_VariantsLogRatio()
    
        logging.info("Completed variant filtering")  
    
    #set eta transition matrix if file provided
    if eta_file is not None:
        logging.info('Set eta error transition matrix from = %s' % eta_file)
        eta_df = p.read_csv(eta_file, header=0, index_col=0)    
        variant_Filter.eta = eta_df.as_matrix()
     
    if random_select is not None:
        if random_select < variant_Filter.V:
            logging.info('Selected %d random variant positions to infer haplotypes from' % random_select)   
            variant_Filter.select_Random(random_select)
        else:
            logging.info('Not enough variable positions for random selection %d >= %d using all' % (random_select,variant_Filter.V))   
            random_select = None
            
    logging.info('Set second adjustable random seed = %d',args.random_seed)
    prng = RandomState(args.random_seed)
    sampletau.initRNG()
    sampletau.setRNG(args.random_seed)
    
    init_NMFT = inmft.Init_NMFT(variant_Filter.snps_filter,genomes,prng)
    logging.info('Perform NTF initialisation')
    init_NMFT.factorize()
    
    haplo_SNP = hsnp.HaploSNP_Sampler(variant_Filter.snps_filter,genomes,prng,max_iter=no_iter)
    
    haplo_SNP.tau = np.copy(init_NMFT.get_tau(),order='C') #Necessary to have C-order for passing to Cython 
    
    haplo_SNP.updateTauIndices()
    
    haplo_SNP.gamma = np.copy(init_NMFT.get_gamma(),order='C')
    
    haplo_SNP.eta = np.copy(variant_Filter.eta,order='C')
     
    logging.info('Start Gibbs sampler burn-in phase')
    haplo_SNP.update()
    #after burn-in phase remove degeneracies
    haplo_SNP.removeDegenerate()
    logging.info('Start Gibbs sampler sampling phase')
    haplo_SNP.update()
    
    #output results to files
    output_Results.set_Variants(variants)
    
    output_Results.set_Variant_Filter(variant_Filter)
    
    output_Results.set_haplo_SNP(haplo_SNP,genomes)
    
    output_Results.output_Filtered_Tau(haplo_SNP.tau_star)

    #compute estimate of posterior probabilities over tau
    meanTau = haplo_SNP.tauMean()
    output_Results.output_Tau_Mean(meanTau)
    
    output_Results.output_Gamma(haplo_SNP.gamma_star)
    
    gamma_mean = haplo_SNP.gammaMean()
    output_Results.output_Gamma_Mean(gamma_mean)
    
    output_Results.output_Eta(haplo_SNP.eta_star)
    
    eta_mean = haplo_SNP.etaMean()
    output_Results.output_Eta_Mean(eta_mean)
    
    output_Results.output_Selected_Variants()
    
    #If we selected random set now assign the rest
    if random_select is not None:
        VS = variant_Filter.snps_filter_original.shape[0] 
        
        snps_notselected = variant_Filter.snps_filter_original[variant_Filter.selected != True,:]
        
        init_NMFT_NS = inmft.Init_NMFT(snps_notselected,haplo_SNP.G,haplo_SNP.randomState)
        
        init_NMFT_NS.gamma = np.transpose(haplo_SNP.gamma)
        logging.info('Perform NTF initialisation on not selected SNPs fixed gamma')
        init_NMFT_NS.factorize_tau()
        
        haplo_SNP_NS = hsnp.HaploSNP_Sampler(snps_notselected,haplo_SNP.G,haplo_SNP.randomState,max_iter=no_iter)
    
        haplo_SNP_NS.tau = init_NMFT_NS.get_tau()
        haplo_SNP_NS.updateTauIndices()
        haplo_SNP_NS.gamma_star = np.copy(haplo_SNP.gammaMean(),order='C')
        haplo_SNP_NS.eta_star = np.copy(haplo_SNP.etaMean(),order='C')  
           
        logging.info('Start Gibbs sampler burn-in phase')
        haplo_SNP_NS.updateTau()
        logging.info('Start Gibbs sampler sampling phase')
        haplo_SNP_NS.updateTau()

        output_Results.output_collated_Tau(haplo_SNP_NS,variants)
    #assign if assignment file given
    if(assign_file != None):
        assigns    = p.read_csv(assign_file, header=0, index_col=0)    
        assigns_matrix = assigns.as_matrix()
        assigns_matrix = np.delete(assigns_matrix, 0, 1)
        import ipdb; ipdb.set_trace()
       
        (assignTau,confTau) = haplo_SNP.assignTau(assigns_matrix)
        snda = haplo_SNP.calculateSND(assignTau)
        
        assign_contig_names = assigns.index.tolist()
        assign_position = assigns['Position']
        
        AV = assigns_matrix.shape[0]
        assign_tau_res = np.reshape(assignTau,(AV,haplo_SNP.G*4))
        assign_tau_df = p.DataFrame(assign_tau_res,index=assign_contig_names)
        conf_tau_df = p.DataFrame(confTau,index=assign_contig_names)
        
        assign_tau_df['Position'] = assign_position
        conf_tau_df['Position'] = assign_position
        
        cols = assign_tau_df.columns.tolist()
        cols = cols[-1:] + cols[:-1]
        
        assign_tau_df = assign_tau_df[cols]
        assign_tau_df.to_csv(output_dir+"/Assigned_Tau_star.csv")
    
        cols = conf_tau_df.columns.tolist()
        cols = cols[-1:] + cols[:-1]
        
        conf_tau_df = conf_tau_df[cols]
        conf_tau_df.to_csv(output_dir+"/Assigned_Tau_conf.csv")
    
    sampletau.freeRNG()
if __name__ == "__main__":
    main(sys.argv[1:])
